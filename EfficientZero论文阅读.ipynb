{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "045f7a40",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Self-Supervised Consistency Loss\n",
    "\n",
    "* Exploring Simple Siamese Representation Learning / Algorithm 1 SimSiam Pseudocode, PyTorch-like\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f380a7f5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Self-Supervised Consistency Loss\n",
    "\n",
    "* Exploring Simple Siamese Representation Learning / Fig. 1\n",
    "* 输入：two randomly augmented views $x_1$ and $x_2$ from an image $x$\n",
    "* encoder $f$\n",
    "    1. a backbone\n",
    "    1. a projection MLP head\n",
    "* predictor $h$ / MLP\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85382907",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Siamese\n",
    "\n",
    "* 连体双胞胎的\n",
    "\n",
    "* $p_1\\triangleq h(f(x_1))$ and $z_2\\triangleq f(x_2)$\n",
    "* negative cosine similarity\n",
    "$$\n",
    "\\mathcal{D}(p_1,z_2)=-\\frac{p_1}{\\|p_1\\|}\\cdot\\frac{z_2}{\\|z_2\\|}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac81f978",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Siamese\n",
    "\n",
    "* symmetrized loss\n",
    "$$\n",
    "\\mathcal{L}=\\frac{1}{2}\\mathcal{D}(p_1,\\mathrm{stopgradient}(z_2))+\\frac{1}{2}\\mathcal{D}(p_2, \\mathrm{stopgradient}(z_1))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dc9ffc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hypothesis\n",
    "\n",
    "* \n",
    "$$\n",
    "\\mathcal{L}(\\theta,\\eta)=\\mathop{\\mathbb{E}}_{x,\\mathcal{T}}\\bigl[\\|\\mathcal{F}_\\theta(\\mathcal{T}(x))-\\eta_x\\|^2\\bigr]\n",
    "$$\n",
    "* $\\mathcal{F}$ is a network parameterized by $\\theta$\n",
    "* $\\mathcal{T}$ is the augmentation\n",
    "* $x$ is an image\n",
    "* $\\eta_x$ is the representation of the image $x$ (intuitively)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067a7894",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hypothesis\n",
    "\n",
    "* \n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\theta^t&\\gets \\mathop{\\arg\\,\\min}_\\theta\\mathcal{L}(\\theta,\\eta^{t-1})\\\\\n",
    "\\eta^t&\\gets \\mathop{\\arg\\,\\min}_\\eta\\mathcal{L}(\\theta^t,\\eta)\n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13c1eb0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hypothesis\n",
    "\n",
    "* minimize $\\mathop{\\mathbb{E}}_\\mathcal{T}\\bigl[\\|\\mathcal{F}_{\\theta^t}(\\mathcal{T}(x))-\\eta_x\\|^2\\bigr]$\n",
    "* easy to solve by \n",
    "$$\n",
    "\\eta^t_x\\gets \\mathop{\\mathbb{E}}_\\mathcal{T}\\bigl[\\mathcal{F}_{\\theta^t}(\\mathcal{T}(x))\\bigr]\n",
    "$$\n",
    "\n",
    "$\\eta_x$ is assigned with the average representation of $x$ over the distribution of augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9a127",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hypothesis\n",
    "\n",
    "* ignoring $\\mathop{\\mathbb{E}}_\\mathcal{T}[\\cdot]$\n",
    "$$\n",
    "\\eta^t_x\\gets \\mathcal{F}_{\\theta^t}(\\mathcal{T'}(x))\n",
    "$$\n",
    "* One-step alternation\n",
    "$$\n",
    "\\theta^{t+1}\\gets \\mathop{\\arg\\,\\min}_\\theta\\mathop{\\mathbb{E}}_{x,\\mathcal{T}}\\bigl[\\|\\mathcal{F}_\\theta(\\mathcal{T}(x))-\\mathcal{F}_{\\theta^t}(\\mathcal{T'}(x))\\|^2\\bigr]\n",
    "$$\n",
    "* the expectation $\\mathop{\\mathbb{E}}_\\mathcal{T}[\\cdot]$ is ignored / The usage of $h$ may fill this gap. / learn to predict the expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa2ff77",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Self-Supervised Consistency Loss\n",
    "\n",
    "* taking **one-step** rollout as an example\n",
    "* $$\\mathcal{L}_\\mathrm{similarity}(s_{t+1},\\hat{s}_{t+1})=\\mathcal{L}_2(sg(P_1(s_{t+1})),P_2(P_1(\\hat{s}_{t+1})))$$\n",
    "* $\\mathcal{L}_2$ is the negtive cosine similarity loss\n",
    "* $sg(P_1)$ means stopping gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87825890",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Self-Supervised Consistency Loss\n",
    "\n",
    "* dynamics network\n",
    "    * MuZero中为：$r^k,s^k=g_\\theta(s^{k-1},a^k)$\n",
    "    * EfficientZero中为：$\\hat{s}_{t+1}=\\mathcal{G}(s_t,a_t)$\n",
    "* representation network\n",
    "    * MuZero中为：$s^0=h_\\theta(o_1,\\dotsc,o_t)$\n",
    "    * EfficientZero中为：$s_t=\\mathcal{H}(o_t),s_{t+1}=\\mathcal{H}(o_{t+1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f4d1fc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## End-To-End Prediction of the Value Prefix\n",
    "\n",
    "* MuZero\n",
    "    * Monte-Carlo tree search (Appendix B Search)\n",
    "    * Backup中：\n",
    "    $$\n",
    "    G^k=\\sum_{\\tau=0}^{l-1-k}\\gamma^\\tau r_{k+1+\\tau}+\\gamma^{l-k}v^l\n",
    "    $$\n",
    "    * $r^k,s^k=g_\\theta(s^{k-1},a^k)$ / the compounding error in the recurrent rollouts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f51463",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* EfficientZero\n",
    "    * $$Q(s_t,a)=\\sum_{i=0}^{k-1}\\gamma^ir_{t+i}+\\gamma^kv_{t+k}$$\n",
    "    * $r_{t+i}$ is the reward **predicted** from unrolled state $\\hat{s}_{t+i}$\n",
    "    * value prefix $\\sum_{i=0}^{k-1}\\gamma^ir_{t+i}$\n",
    "    * *value prefix* prediction network: $r_t,h_{t+1}=\\mathcal{R}(\\hat{s}_{t+1},h_t)$\n",
    "        * why $h_t$? LSTM.\n",
    "        * how to train? $\\mathcal{L}(u_t,r_t)$, where $\\mathcal{L}$ is the total loss of the unrolled 5 steps\n",
    "        * $u_t$ is the reward from the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eb0626",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## End-To-End Prediction of the Value Prefix\n",
    "\n",
    "* Mastering Atari Games with Limited Data / Fig. 3\n",
    "* If we only see **the first observation**, along with **future actions**, it is **very hard** both for an agent and a human to predict at which **exact** future timestep the player would lose a point.\n",
    "* value prefix $\\sum_{i=0}^{k-1}\\gamma^ir_{t+i}$ is -1\n",
    "* which $r_{t+i}$ is -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d34419",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* However, it is easy to predict the agent will miss the ball after a sufficient number of timesteps if he does not move."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
